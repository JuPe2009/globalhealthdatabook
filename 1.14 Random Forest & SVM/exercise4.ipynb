{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Model fitting and performance evaluation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import random forest model \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the previous operations on data\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv(\"./imputed_data.csv\", index_col=0)\n",
    "features = data.iloc[:, 3:-1]\n",
    "features = pd.get_dummies(features).values\n",
    "labels = data.mort_icu.values\n",
    "train_features, test_features, train_labels, test_labels = \\\n",
    "                                    train_test_split(features, labels, test_size = 0.25, random_state = 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model fitting \n",
    "\n",
    "As discussed in background, random forest is the meta model which uses a number of decision tree classifiers to fit on sub-samples of the dataset. In addition, it averages the results from the decision trees to improve the accuracy and control overfitting. \n",
    "\n",
    "The workflow of model fitting is as following:\n",
    "\n",
    "+ Define the model parameters\n",
    "+ Feed in the training features and labels to fit the model \n",
    "+ Feed in the testing features to your fitted model and compute the predicitions. \n",
    "+ Evaluate the testing labels with the predictions on the proper metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model\n",
    "\n",
    "We are using RandomForestClassifier from [scikit-learn](https://scikit-learn.org/stable/index.html) Python package. The detailed documentation of RandomForestClassifier can be found at [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). For a clinical problem, we commonly adjust the following parameters to obtain a good model: \n",
    "\n",
    "+ n_estimators: number of decision trees\n",
    "+ max_features: max number of features considered for splitting a node\n",
    "+ max_depth: max number of levels in each decision tree\n",
    "+ min_samples_split: min number of data points placed in a node before the node is split\n",
    "+ min_samples_leaf: min number of data points allowed in a leaf node\n",
    "+ bootstrap: method for sampling data points (with or without replacement)\n",
    "\n",
    "We may review the literatures related to the clincial problem to define these parameters or use a grid search method. In this example, we use the default hyperparameters with 100 estimators first to try the performance first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with default 100 decision trees\n",
    "model = RandomForestClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed training data and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling fitting on training set. \n",
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed in testing data and compute predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performace\n",
    "\n",
    "We use the following metrics to evaluate the performance of fitted model\n",
    "\n",
    "+ Accuracy\n",
    "+ Area under Receiver Operating Characteristic (AUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is 93.40 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc = accuracy_score(test_pred, test_labels)\n",
    "print(\"The testing accuracy is {:.2f} %\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing AUROC is 0.83\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test_pred, test_labels)\n",
    "print(\"The testing AUROC is {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Fitting\n",
    "\n",
    "In SVM model fitting, the workflow will be as same as fitting a random forest model. The only difference we need to consider is the hyperparameter tunning for SVM. We commonly will adjust the following hyperparameters for SVM:\n",
    "+ C: Penalty parameter C of the error term.\n",
    "+ kernel : Kernel type of the model, one of 'linear', 'poly', 'rbf', 'sigmoid' or 'precomputed'. \n",
    "+ gamma : The coefficient for 'rbf', 'poly' and 'sigmoid' kernels. \n",
    "\n",
    "We use default hyperparameters first in this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting. The fitting may take some time due to the large number of patients in the dataset. \n",
    "svm.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = svm.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is 92.66 %\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(test_pred, test_labels)\n",
    "print(\"The testing accuracy is {:.2f} %\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing AUROC is 0.96\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test_pred, test_labels)\n",
    "print(\"The testing AUROC is {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further readings\n",
    "\n",
    "To obtain a good model, the hyper-parameters in \"Define the model\" section must be properly adjusted. To further learn about hyper-parameters of random forest, please refer to following online materials: \n",
    "\n",
    "- Hyperparameter Tuning the Random Forest in Python [https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74]\n",
    "\n",
    "- Tuning the parameters of your Random Forest model. [https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
